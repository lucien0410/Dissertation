ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0),
f2=c(0,1)
)
b <- .1						#initial bias
w <- .2						#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0),
f2=c(0,1)
)
b <- .2						#initial bias
w <- .2						#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
df2
r
x
d
df2[r,1]
df2 <- data.frame(
f1=c(1,0),
f2=c(0,1)
)
df2[r,1]
df2[r,2]
x <- df2[r,1]
x
d <- df2[r,2]
d
df2
y <- x*w + b
y
b <- .2						#initial bias
w <- .2						#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
y <- x*w + b
y
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0),
f2=c(0,1)
)
b <- 10						#initial bias
w <- 10					#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
df
df2
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0,10),
f2=c(0,1,2)
)
b <- 10						#initial bias
w <- 10					#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0,10,2),
f2=c(0,1,2,3)
)
b <- 10						#initial bias
w <- 10					#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
#perceptron learning demo
#sample data
#map 0 to 1 and 1 to 0
df2 <- data.frame(
f1=c(1,0,10,2),
f2=c(0,1,2,3)
)
b <- .1						#initial bias
w <- .2					#initial weight
bs <- c(b)					#record of biases
ws <- c(w)					#record of weights
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
#set limits for y-axis
ymax <- max(c(bs,ws))+1
ymin <- min(c(bs,ws))-1
#plot bias change
plot(
bs,
type='l',
ylim=c(ymax,ymin),
ylab='bias and weight',
col='red'
)
#plot weight change
lines(ws,col='blue')
#add a pretty legend
legend(
'topleft',
legend=c('bias','weight'),
col=c('red','blue'),
lty=1
)
for (i in 1:20) {
print i
}
for (i in 1:20) {
print i}
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
for (i in 1:20) {			#how many iterations
for (r in 1:nrow(df2)) {
x <- df2[r,1]		#input
d <- df2[r,2]		#label/output
y <- x*w + b		#actual output
w <- w + (d-y)*x	#new weight
ws <- c(ws,w)		#save new weight
b <- b + (d-y)		#new bias
bs <- c(bs,b)		#save new bias
}
}
for (i in 1:20) {			#how many iterations
print i
}
for (i in 1:20) {			#how many iterations
k<-49
}
for (i in 1:20) {			#how many iterations
print 'x'
}
for (i in 1:20) {			#how many iterations
print(i)
}
n
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
pwd
cd
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
getwd
getwd()
setwd('/home/yuan-lu/Dropbox/google_drive/gaelic/disertation')
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
n
install.packages(""xtable"")
install.packages("xtable")
plot(n)
xtable(n)
n.xtable
n.xtable()
print(n)
xtable(n)
xtable
import xtable
import xtable::align(n['gd'])
import xtable::align()
require(xtable)
xtable(n)
n
m=c('M', 12 ,34)
m
n+m
summary(n)
k=rbind(n,m)
k
m
n
mean(gd)
gd<-n['gd'][,]
gloss<-n['gloss'][,]
mean(gd)
sd(gd)
mean(gloss)
sd(gloss)
t.test(gd, gloss,paired=TRUE)
library(devtools)
install.packages("devtools")
library(devtools)
install_github('jimhester/lintr')
library(devtools)
install.packages("devtools")
install.packages("RCurl")
install.packages("curl")
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][,]
gloss<-n['GLOSS'][,]
mean(gd)
sd(gd)
mean(gloss)
sd(gloss)
r <-t.test(gd, gloss,paired=TRUE)
r
r <-t.test(gloss gd,paired=TRUE)
r <-t.test( gloss, gd, paired=TRUE)
r
gd
gd[,10]
gd[10,]
gd[,]
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][,]
gloss<-n['GLOSS'][,]
m_gd <- mean(gd)
m_gloss <- mean(gloss)
sd_gd <- sd(gd)
sd_gloss <- sd(gloss)
r <-t.test( gloss, gd, paired=TRUE)
r
gd
gd[:9]
gd[9]
gd[,9]
gd[9,]
gd[9:,]
gd[1:9,]
gd[,1:9]
gd
gd[1,2]
gd[1,1]
gd[1]
gd[9]
gd[1:9]
gd
gd[:10]
gd[1:10]
r <-t.test( gloss[1:10], gd[1:10], paired=TRUE)
r
gd
gd[,]
n['GLOSS']
gd<-n['Gaelic']
gd
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
#gd<-n['Gaelic'][,]
#gloss<-n['GLOSS'][,]
gd<-n['Gaelic']
gloss<-n['GLOSS']
m_gd <- mean(gd)
gd
gd[0]
gd[0][1]
gd
gd[0:1]
gd[1]
gd[0]
gd
gd[,]
gd<-n['Gaelic'][,][:10]
gd<-n['Gaelic'][,][1:10]
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][,][1:10]
gloss<-n['GLOSS'][,][1:10]  # [11] is MEAN
m_gd <- mean(gd)
m_gloss <- mean(gloss)
sd_gd <- sd(gd)
sd_gloss <- sd(gloss)
r <-t.test( gloss, gd, paired=TRUE)
r
m_gd
sd_gd
sd_gloss
m_gloss
n['Gaelic']
n['Gaelic'][,1]
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][,1][1:10]
gloss<-n['GLOSS'][,1][1:10]  # [11] is MEAN
gd
n['Gaelic'][1,1]
n['Gaelic'][1,2]
n['Gaelic'][2,1]
n['Gaelic']
n['Gaelic'][1,]
n['Gaelic'][,:10]
n['Gaelic'][,0:10]
n['Gaelic'][,1:10]
n['Gaelic'][1,1:10]
n['Gaelic'][1,1]
n['Gaelic'][2,1]
n['Gaelic'][:10,1]
n['Gaelic'][1:10,1]
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][1:10,1]
gloss<-n['GLOSS'][1:10,1]  # [11,1] is MEAN
m_gd <- mean(gd)
m_gloss <- mean(gloss)
sd_gd <- sd(gd)
sd_gloss <- sd(gloss)
r <-t.test( gloss, gd, paired=TRUE)
apply(gloss,mean)
apply(gloss,1,mean)
install.packages('rnn')
rnn
library(rnn)
rnn
n <- read.csv('gd-to-en_gloss-to-en.tsv', sep='\t', header = TRUE)
gd<-n['Gaelic'][1:10,1]
gloss<-n['GLOSS'][1:10,1]  # [11,1] is MEAN
m_gd <- format(round(mean(gd), 2), nsmall = 2)
m_gloss <- format(round(mean(gloss), 2), nsmall = 2)
sd_gd <- format(round(sd(gd), 2), nsmall = 2)
sd_gloss <- format(round(sd(gloss), 2), nsmall = 2)
r <-t.test( gloss, gd, paired=TRUE)
r
summary(r)
r
r.t()
r
r$statistic
r$method
r$parameter
r$parameter$df
r$parameter[df]
r$parameter
r$statistic
r$p.value

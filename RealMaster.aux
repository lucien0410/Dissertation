\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{luong17GitHub}
\citation{roweis2000nonlinear}
\citation{luong17GitHub}
\citation{luong2015effective}
\citation{luong17GitHub}
\citation{koehn2009statistical}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{9}{Doc-Start}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{10}{Doc-Start}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{toc}{\contentsline {chapter}{Abstract}{11}{Doc-Start}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 1}Introduction}{12}{chapter.1}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:Introduction}{{1}{12}{Introduction}{chapter.1}{}}
\citation{sneddon2012indonesian}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 2}What are glosses? Why are they golden representations of meanings?}{13}{chapter.2}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:gloss}{{2}{13}{What are glosses? Why are they golden representations of meanings?}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction: What are Glosses?}{13}{section.2.1}}
\newlabel{gloss_eg}{{1}{13}{Introduction: What are Glosses?}{Item.7}{}}
\citation{bickel2008leipzig}
\citation{grano2008mandarin}
\citation{Chen2010}
\citation{liu2010positive}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}The Golden Properties of Glosses}{15}{section.2.2}}
\newlabel{gold_to_gd}{{4a}{15}{The Golden Properties of Glosses}{Item.11}{}}
\newlabel{gold_to_gl}{{4b}{15}{The Golden Properties of Glosses}{Item.12}{}}
\newlabel{gd_gl_comp1}{{4c}{15}{The Golden Properties of Glosses}{Item.13}{}}
\newlabel{gd_to_gold}{{5a}{16}{The Golden Properties of Glosses}{Item.15}{}}
\newlabel{gl_to_gold}{{5b}{16}{The Golden Properties of Glosses}{Item.16}{}}
\newlabel{gd_gl_comp2}{{5c}{16}{The Golden Properties of Glosses}{Item.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Glosses Cluster Different Words with the Same Meanings (Synonyms) Into a Single representation}{16}{subsection.2.2.1}}
\newlabel{sec:cluster}{{2.2.1}{16}{Glosses Cluster Different Words with the Same Meanings (Synonyms) Into a Single representation}{subsection.2.2.1}{}}
\citation{kratzer1998semantics}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\citation{zhang2013classifier}
\citation{zhang2013classifier}
\newlabel{chinese_cl_eg}{{14}{18}{Glosses Cluster Different Words with the Same Meanings (Synonyms) Into a Single representation}{Item.26}{}}
\citation{adger2003core}
\citation{lamb2001scottish}
\citation{lamb2001scottish}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Glosses Distinguish Homographs' Different Meanings}{19}{subsection.2.2.2}}
\newlabel{sec:disa}{{2.2.2}{19}{Glosses Distinguish Homographs' Different Meanings}{subsection.2.2.2}{}}
\newlabel{for_eng}{{15}{19}{Glosses Distinguish Homographs' Different Meanings}{Item.27}{}}
\newlabel{for_c}{{15a}{19}{Glosses Distinguish Homographs' Different Meanings}{Item.28}{}}
\newlabel{for_p}{{15b}{19}{Glosses Distinguish Homographs' Different Meanings}{Item.29}{}}
\newlabel{a_prog}{{16}{19}{Glosses Distinguish Homographs' Different Meanings}{Item.30}{}}
\newlabel{a_det}{{17}{19}{Glosses Distinguish Homographs' Different Meanings}{Item.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{19}{subsection.2.2.3}}
\citation{berwick2015only}
\citation{berwick2015only}
\citation{berwick2015only}
\newlabel{tree}{{19}{20}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.33}{}}
\newlabel{aux_inver1}{{20a}{20}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.35}{}}
\newlabel{aux_inver2}{{20b}{20}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.36}{}}
\citation{cheng1973synchronic,mei1991tone,shih1997mandarin,wang2011variation}
\newlabel{aux_inver3}{{20c}{21}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.37}{}}
\citation{Syntax_to_Translation}
\citation{Semantic_Role_Labeling}
\newlabel{hao1}{{23}{22}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.48}{}}
\newlabel{hao2}{{24}{22}{Glosses are Sensitive to Hierarchical Structures in Natural Language Sentences}{Item.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Conclusion: What Is a Gloss Line and Why Do They Matter?}{23}{section.2.3}}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 3}A General Introduction of Machine Learning and Machine Translation}{24}{chapter.3}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:MT}{{3}{24}{A General Introduction of Machine Learning and Machine Translation}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}What is Machine Learning?}{24}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}What is a Function and What is a Model?}{24}{subsection.3.1.1}}
\newlabel{math_function}{{26}{25}{What is a Function and What is a Model?}{Item.55}{}}
\newlabel{fun_dipc}{{29a}{26}{What is a Function and What is a Model?}{Item.73}{}}
\newlabel{model_dipc}{{29b}{26}{What is a Function and What is a Model?}{Item.74}{}}
\citation{pyle2015executive}
\citation{domingos2012few}
\citation{mitchell2006discipline}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Two Different Paradigms of Building a Model}{27}{subsection.3.1.2}}
\citation{chomsky2007}
\citation{chom2005_three_factors}
\citation{brown1988statistical,brown1990statistical,brown1993mathematics,koehn2009statistical,moses}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Statistical Machine Translation}{28}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Neural Net Machine Translation}{30}{section.3.3}}
\newlabel{neural_MT}{{3.3}{30}{Neural Net Machine Translation}{section.3.3}{}}
\citation{rosenblatt}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}What Is a Artificial Neural Network?}{31}{subsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces An Example of a Perceptron}}{31}{figure.3.1}}
\citation{siegelmann1991turing,graves2014neural}
\citation{siegelmann2003neural,siegelmann2012neural}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Activation functions}}{32}{figure.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A neural network with a hidden layer}}{33}{figure.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Recurrent Neural Network}{33}{subsection.3.3.2}}
\citation{luong17GitHub}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A recurrent neural network with a hidden layer. The hidden neuron ($h$) is connected to itself.}}{34}{figure.3.4}}
\newlabel{fig:rnn1}{{3.4}{34}{A recurrent neural network with a hidden layer. The hidden neuron ($h$) is connected to itself}{figure.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Introduction to Neural Net Machine Translation}{34}{section.3.4}}
\citation{luong17GitHub}
\citation{luong17GitHub}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces A recurrent neural network with a hidden layer (unfolded depiction). This figure depicts exactly the same structure in figure \ref  {fig:rnn1}, the hidden neuron $h_{t}$ is linked to its past $h_{t-1}$ and its future $h_{t+1}$. Here $t$ labels time step.}}{35}{figure.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Encoder-decoder architecture - example of a general approach for NMT. An encoder converts a source sentence into a "meaning" vector which is passed through a decoder to produce a translation. (figure from \citet  {luong17GitHub})}}{35}{figure.3.6}}
\citation{mikolov2013efficient,mikolov2013distributed}
\citation{roweis2000nonlinear}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Word Embedding}{36}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Encoding and Decoding}{36}{subsection.3.4.2}}
\citation{luong17GitHub}
\citation{luong17GitHub}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Word Embeddings (figure from \citet  {roweis2000nonlinear})}}{37}{figure.3.7}}
\citation{cho2014properties,cho2014learning}
\citation{bahdanau2014neural}
\citation{luong2015effective}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Neural machine translation (figure from \citet  {luong17GitHub}).}}{38}{figure.3.8}}
\citation{luong17GitHub}
\citation{luong2015effective}
\citation{luong17GitHub}
\citation{luong2015effective}
\citation{luong17GitHub}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Adding Attention Mechanism}{39}{subsection.3.4.3}}
\citation{pierce1966language}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Attention mechanism - example of an attention-based NMT system as described in \citet  {luong2015effective} (figure from \citet  {luong17GitHub})}}{40}{figure.3.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Summary of Neural Net Machine Translation: interlingua plus string alignment}{40}{subsection.3.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}A Quick Historical Overview of Machine Translation and Conclusion}{41}{section.3.5}}
\citation{kotsiantis2007supervised}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 4}Building Translation Systems using Interlinear Glossed Text: First Attempt}{42}{chapter.4}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:cake}{{4}{42}{Building Translation Systems using Interlinear Glossed Text: First Attempt}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{42}{section.4.1}}
\newlabel{gloss_helps_hypothesis}{{34}{42}{Introduction}{Item.82}{}}
\citation{williams2016syntax}
\citation{sennrich2016linguistic}
\citation{ccg_target_seq}
\citation{2017opennmt}
\citation{cho2014properties,cho2014learning,bahdanau2014neural}
\newlabel{strong_hy}{{34a}{43}{Introduction}{Item.83}{}}
\newlabel{weak_hy}{{34b}{43}{Introduction}{Item.84}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Related Work}{43}{section.4.2}}
\newlabel{relate_work}{{4.2}{43}{Related Work}{section.4.2}{}}
\citation{DBLP:journals/corr/KeskarMNST16}
\citation{DBLP:journals/corr/abs-1711-00489}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Technical Settings of the Machine Translation Experiments and Experimental Data of Scottish Gaelic Interlinear Glossed Text Corpus}{44}{section.4.3}}
\newlabel{sec:experimet_setting}{{4.3}{44}{Technical Settings of the Machine Translation Experiments and Experimental Data of Scottish Gaelic Interlinear Glossed Text Corpus}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Technical Settings}{44}{subsection.4.3.1}}
\citation{gaelic_igt}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Experimental Data: a corpus of Scottish Gaelic Interlinear Glossed Texts}{46}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Gloss Representation Solely Does NOT Outperform Gaelic Sentences}{46}{section.4.4}}
\newlabel{gd_to_gl_to_en}{{4.4}{46}{Gloss Representation Solely Does NOT Outperform Gaelic Sentences}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Procedure of the Experiments}{46}{subsection.4.4.1}}
\newlabel{GLOSStoENTrain}{{38a}{47}{Procedure of the Experiments}{Item.92}{}}
\newlabel{GLOSStoENVal}{{38b}{47}{Procedure of the Experiments}{Item.93}{}}
\newlabel{GLOSStoENTest}{{38c}{47}{Procedure of the Experiments}{Item.94}{}}
\newlabel{GDtoENTrain}{{39a}{48}{Procedure of the Experiments}{Item.97}{}}
\newlabel{GDtoENVal}{{39b}{48}{Procedure of the Experiments}{Item.98}{}}
\newlabel{GDtoENTest}{{39c}{48}{Procedure of the Experiments}{Item.99}{}}
\newlabel{ModelGlossToEN}{{40a}{48}{Procedure of the Experiments}{Item.102}{}}
\newlabel{ModelGDToEN}{{40b}{48}{Procedure of the Experiments}{Item.103}{}}
\citation{Snover06astudy}
\citation{damerau1964technique,levenshtein1966binary}
\citation{bleu}
\citation{moses}
\newlabel{gold1}{{42a}{49}{Procedure of the Experiments}{Item.108}{}}
\newlabel{can1}{{42b}{49}{Procedure of the Experiments}{Item.109}{}}
\newlabel{can2}{{42c}{49}{Procedure of the Experiments}{Item.110}{}}
\newlabel{bi_gold1}{{45a}{50}{Procedure of the Experiments}{Item.116}{}}
\citation{koehn2009statistical}
\citation{koehn2009statistical}
\citation{koehn2009statistical}
\newlabel{bi_can1}{{45b}{51}{Procedure of the Experiments}{Item.117}{}}
\newlabel{bi_can2}{{45c}{51}{Procedure of the Experiments}{Item.118}{}}
\newlabel{bleu_koeh}{{4.4.1}{52}{Procedure of the Experiments}{equation.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The BLEU score is based on n-gram matches with the reference translation \citep  [p. 226-227]{koehn2009statistical}}}{52}{figure.4.1}}
\newlabel{bleu_koeh}{{4.1}{52}{The BLEU score is based on n-gram matches with the reference translation \citep [p. 226-227]{koehn2009statistical}}{figure.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Result}{53}{subsection.4.4.2}}
\newlabel{gdglen_results}{{4.4.2}{53}{Result}{subsection.4.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {GLOSStoEn}}}{53}{table.4.1}}
\newlabel{Table:GLOSS}{{4.1}{53}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {GLOSStoEn}}{table.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Summary}{53}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Discussion and Conclusion}{54}{section.4.5}}
\newlabel{section:cake1_Discussion}{{4.5}{54}{Discussion and Conclusion}{section.4.5}{}}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 5}Combining Gaelic Words with Glosses}{56}{chapter.5}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:cake2}{{5}{56}{Combining Gaelic Words with Glosses}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{56}{section.5.1}}
\citation{luong2015multi}
\citation{google_zero_shot}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}The Underlying Heuristics}{57}{subsection.5.1.1}}
\newlabel{heuristics}{{5.1.1}{57}{The Underlying Heuristics}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}The `Parallel-Partial' Treatment Outperforms Any Other Treatments and the Baseline Significantly}{57}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Related work}{57}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Data Preprocessing Using the Parallel-Partial Treatment}{58}{subsection.5.2.2}}
\newlabel{sample_para}{{51}{58}{Data Preprocessing Using the Parallel-Partial Treatment}{Item.132}{}}
\newlabel{sample_partial}{{52}{59}{Data Preprocessing Using the Parallel-Partial Treatment}{Item.136}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Results of the Parallel-Partial Treatment}{59}{subsection.5.2.3}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {ParaParttoEn}}}{60}{table.5.1}}
\newlabel{Table:ParaPart}{{5.1}{60}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {ParaParttoEn}}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{60}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Other Possible Treatments}{60}{section.5.3}}
\citation{bahdanau2014neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}The Parallel Treatment}{61}{subsection.5.3.1}}
\newlabel{treatment:Para}{{5.3.1}{61}{The Parallel Treatment}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Method of the Parallel Treatment}{61}{section*.2}}
\newlabel{igt}{{53}{61}{Method of the Parallel Treatment}{Item.145}{}}
\newlabel{sample_pair}{{54}{61}{Method of the Parallel Treatment}{Item.146}{}}
\newlabel{treatment:Para_result}{{5.3.1}{61}{Results of the Parallel Treatment}{section*.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Results of the Parallel Treatment}{61}{section*.3}}
\citation{ccg_target_seq}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {ParatoEn}}}{62}{table.5.2}}
\newlabel{Table:Para}{{5.2}{62}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {ParatoEn}}{table.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN}, Model\textsubscript  {ParatoEN} and Model\textsubscript  {ParaParttoEN} }}{62}{table.5.3}}
\newlabel{Table:Concating}{{5.3}{62}{BLEU scores of Model\textsubscript {GDtoEN}, Model\textsubscript {ParatoEN} and Model\textsubscript {ParaParttoEN}}{table.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Interleaving Gaelic Words and Gloss Items And Concating them}{62}{subsection.5.3.2}}
\newlabel{treatment:InterleavingAndConCat}{{5.3.2}{62}{Interleaving Gaelic Words and Gloss Items And Concating them}{subsection.5.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Method of the Interleaving Treatment}{62}{section*.4}}
\newlabel{ex_interleave:in}{{55a}{63}{Method of the Interleaving Treatment}{Item.150}{}}
\newlabel{ex_interleave:out}{{55b}{63}{Method of the Interleaving Treatment}{Item.151}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {interleavingGdGLOSStoEn}}}{63}{table.5.4}}
\newlabel{Table:interleavingGdGLOSS}{{5.4}{63}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {interleavingGdGLOSStoEn}}{table.5.4}{}}
\newlabel{treatment:Concating}{{5.3.2}{64}{Method of Concatenating Gaelic Words and Gloss Words}{section*.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Method of Concatenating Gaelic Words and Gloss Words }{64}{section*.5}}
\@writefile{toc}{\contentsline {subsubsection}{Results of Concating Gaelic Words and Gloss Words}{64}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Hybrid: Gaelic or Gloss}{64}{subsection.5.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{Method of Hybrid}{64}{section*.7}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {ConcatGLOSSGaelictoEn} }}{65}{table.5.5}}
\newlabel{Table:Concating}{{5.5}{65}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {ConcatGLOSSGaelictoEn}}{table.5.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {HybridDefaultAsGaelictoEn}}}{66}{table.5.6}}
\newlabel{Table:HybridDefaultAsGaelic}{{5.6}{66}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {HybridDefaultAsGaelictoEn}}{table.5.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Result of Hybrid}{66}{table.5.6}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces BLEU scores of Model\textsubscript  {GDtoEN} and Model\textsubscript  {HybridDefaultAsGLOSS}}}{67}{table.5.7}}
\newlabel{Table:HybridDefaultAsGLOSS}{{5.7}{67}{BLEU scores of Model\textsubscript {GDtoEN} and Model\textsubscript {HybridDefaultAsGLOSS}}{table.5.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Summary and Conclusion}{67}{section.5.4}}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces BLEU scores of the all treatments}}{68}{table.5.8}}
\newlabel{table:complete_table}{{5.8}{68}{BLEU scores of the all treatments}{table.5.8}{}}
\citation{google_api}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 6}Tying Up Some Loose Ends}{69}{chapter.6}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\newlabel{chap:Tying_Up}{{6}{69}{Tying Up Some Loose Ends}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Comparison with Google Translation}{69}{section.6.1}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces BLEU scores of Model\textsubscript  {ParaPart} and Google Translation}}{70}{table.6.1}}
\newlabel{Table:google}{{6.1}{70}{BLEU scores of Model\textsubscript {ParaPart} and Google Translation}{table.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Oversampling}{70}{section.6.2}}
\newlabel{over1}{{61a}{70}{Oversampling}{Item.161}{}}
\newlabel{over2}{{61b}{70}{Oversampling}{Item.162}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces BLEU scores of Model\textsubscript  {ParaPart} and Gaelic Treatment with Oversampling}}{71}{table.6.2}}
\newlabel{Table:over}{{6.2}{71}{BLEU scores of Model\textsubscript {ParaPart} and Gaelic Treatment with Oversampling}{table.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Other Hyper-Parameters}{71}{section.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces BLEU scores of Round 0 using different Hyper-Parameters}}{72}{table.6.3}}
\newlabel{Table:HyPara}{{6.3}{72}{BLEU scores of Round 0 using different Hyper-Parameters}{table.6.3}{}}
\citation{ODIN,Xia2016}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Interlinear Glossed Text Data In Other Languages: the Universality}{73}{section.6.4}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces BLEU scores of other languages}}{74}{table.6.4}}
\newlabel{Table:Other_LG_BLEU}{{6.4}{74}{BLEU scores of other languages}{table.6.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Conclusion}{75}{section.6.5}}
\citation{Mohsen}
\@writefile{toc}{\contentsline {chapter}{\chapterline {Chapter\ 7}Conclusion and Future Research}{76}{chapter.7}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lot}{\addvspace {\medskipamount }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Future Research}{76}{section.7.1}}
\citation{pater2017generative}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Conclusion}{77}{section.7.2}}
\bibstyle{te}
\bibdata{ref}
\bibcite{adger2003core}{{1}{2003}{{Adger}}{{}}}
\bibcite{bahdanau2014neural}{{2}{2014}{{Bahdanau et~al.}}{{Bahdanau, Cho, and Bengio}}}
\bibcite{berwick2015only}{{3}{2015}{{Berwick and Chomsky}}{{}}}
\bibcite{bickel2008leipzig}{{4}{2008}{{Bickel et~al.}}{{Bickel, Comrie, and Haspelmath}}}
\bibcite{brown1988statistical}{{5}{1988}{{Brown et~al.}}{{Brown, Cocke, Pietra, Pietra, Jelinek, Mercer, and Roossin}}}
\bibcite{brown1990statistical}{{6}{1990}{{Brown et~al.}}{{Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, and Roossin}}}
\bibcite{brown1993mathematics}{{7}{1993}{{Brown et~al.}}{{Brown, Pietra, Pietra, and Mercer}}}
\bibcite{Chen2010}{{8}{2010}{{Chen}}{{}}}
\bibcite{gaelic_igt}{{9}{2018}{{Chen et~al.}}{{Chen, Carnie, Hammond, and Patton}}}
\bibcite{cheng1973synchronic}{{10}{1973}{{Cheng}}{{}}}
\bibcite{cho2014properties}{{11}{2014{a}}{{Cho et~al.}}{{Cho, Van~Merri{\"e}nboer, Bahdanau, and Bengio}}}
\bibcite{cho2014learning}{{12}{2014{b}}{{Cho et~al.}}{{Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau, Bougares, Schwenk, and Bengio}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{79}{section.7.2}}
\@writefile{lof}{\addvspace {\medskipamount }}
\@writefile{lof}{\addvspace {\medskipamount }}
\bibcite{chom2005_three_factors}{{13}{2005}{{Chomsky}}{{}}}
\bibcite{chomsky2007}{{14}{2007}{{Chomsky}}{{}}}
\bibcite{damerau1964technique}{{15}{1964}{{Damerau}}{{}}}
\bibcite{domingos2012few}{{16}{2012}{{Domingos}}{{}}}
\bibcite{grano2008mandarin}{{17}{2008}{{Grano}}{{}}}
\bibcite{graves2014neural}{{18}{2014}{{Graves et~al.}}{{Graves, Wayne, and Danihelka}}}
\bibcite{google_api}{{19}{2018}{{Han}}{{}}}
\bibcite{google_zero_shot}{{20}{2016}{{Johnson et~al.}}{{Johnson, Schuster, Le, Krikun, Wu, Chen, Thorat, Vi{\'e}gas, Wattenberg, Corrado et~al.}}}
\bibcite{DBLP:journals/corr/KeskarMNST16}{{21}{2016}{{Keskar et~al.}}{{Keskar, Mudigere, Nocedal, Smelyanskiy, and Tang}}}
\bibcite{Syntax_to_Translation}{{22}{2018}{{{Kiperwasser} and {Ballesteros}}}{{}}}
\bibcite{2017opennmt}{{23}{2017}{{Klein et~al.}}{{Klein, Kim, Deng, Senellart, and Rush}}}
\bibcite{koehn2009statistical}{{24}{2009}{{Koehn}}{{}}}
\bibcite{moses}{{25}{2007}{{Koehn et~al.}}{{Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens et~al.}}}
\bibcite{kotsiantis2007supervised}{{26}{2007}{{Kotsiantis et~al.}}{{Kotsiantis, Zaharakis, and Pintelas}}}
\bibcite{kratzer1998semantics}{{27}{1998}{{Kratzer and Heim}}{{}}}
\bibcite{lamb2001scottish}{{28}{2001}{{Lamb}}{{}}}
\bibcite{levenshtein1966binary}{{29}{1966}{{Levenshtein}}{{}}}
\bibcite{ODIN}{{30}{2010}{{Lewis and Xia}}{{}}}
\bibcite{liu2010positive}{{31}{2010}{{Liu}}{{}}}
\bibcite{luong17GitHub}{{32}{2017}{{Luong et~al.}}{{Luong, Brevdo, and Zhao}}}
\bibcite{luong2015multi}{{33}{2015}{{Luong et~al.}}{{Luong, Le, Sutskever, Vinyals, and Kaiser}}}
\bibcite{luong2015effective}{{34}{2014}{{Luong et~al.}}{{Luong, Pham, and Manning}}}
\bibcite{Mohsen}{{35}{2018}{{Mahdavi~Mazdeh}}{{}}}
\bibcite{mei1991tone}{{36}{1991}{{Mei}}{{}}}
\bibcite{mikolov2013efficient}{{37}{2013{a}}{{Mikolov et~al.}}{{Mikolov, Chen, Corrado, and Dean}}}
\bibcite{mikolov2013distributed}{{38}{2013{b}}{{Mikolov et~al.}}{{Mikolov, Sutskever, Chen, Corrado, and Dean}}}
\bibcite{mitchell2006discipline}{{39}{2006}{{Mitchell}}{{}}}
\bibcite{ccg_target_seq}{{40}{2017}{{Nadejde et~al.}}{{Nadejde, Reddy, Sennrich, Dwojak, Junczys-Dowmunt, Koehn, and Birch}}}
\bibcite{bleu}{{41}{2002}{{Papineni et~al.}}{{Papineni, Roukos, Ward, and Zhu}}}
\bibcite{pater2017generative}{{42}{2017}{{Pater}}{{}}}
\bibcite{pierce1966language}{{43}{1966}{{Pierce and Carroll}}{{}}}
\bibcite{pyle2015executive}{{44}{2015}{{Pyle and San~Jose}}{{}}}
\bibcite{rosenblatt}{{45}{1958}{{Rosenblatt}}{{}}}
\bibcite{roweis2000nonlinear}{{46}{2000}{{Roweis and Saul}}{{}}}
\bibcite{sennrich2016linguistic}{{47}{2016}{{Sennrich and Haddow}}{{}}}
\bibcite{shih1997mandarin}{{48}{1997}{{Shih}}{{}}}
\bibcite{siegelmann2003neural}{{49}{2003}{{Siegelmann}}{{}}}
\bibcite{siegelmann2012neural}{{50}{2012}{{Siegelmann}}{{}}}
\bibcite{siegelmann1991turing}{{51}{1991}{{Siegelmann and Sontag}}{{}}}
\bibcite{DBLP:journals/corr/abs-1711-00489}{{52}{2017}{{Smith et~al.}}{{Smith, Kindermans, and Le}}}
\bibcite{sneddon2012indonesian}{{53}{2012}{{Sneddon et~al.}}{{Sneddon, Adelaar, Djenar, and Ewing}}}
\bibcite{Snover06astudy}{{54}{2006}{{Snover et~al.}}{{Snover, Dorr, Schwartz, Micciulla, and Makhoul}}}
\bibcite{Semantic_Role_Labeling}{{55}{2018}{{{Strubell} et~al.}}{{{Strubell}, {Verga}, {Andor}, {Weiss}, and {McCallum}}}}
\bibcite{wang2011variation}{{56}{2011}{{Wang and Lin}}{{}}}
\bibcite{williams2016syntax}{{57}{2016}{{Williams et~al.}}{{Williams, Sennrich, Post, and Koehn}}}
\bibcite{Xia2016}{{58}{2016}{{Xia et~al.}}{{Xia, Lewis, Goodman, Slayden, Georgi, Crowgey, and Bender}}}
\bibcite{zhang2013classifier}{{59}{2013}{{Zhang}}{{}}}

\chapter{Introduction}
\label{chap:Introduction}
\setcounter{exx}{0}
The fundamental argument that I am trying to make in the dissertation is as follows:

\begin{exe}
	\ex Without linguistics, we only have ordinary natural language processing systems. With linguistics, we have extraordinary natural language processing systems. 
\end{exe}

Specifically, the question is whether or not Interlinear Glossed Texts, an everyday tool for linguistic studies, can help machine translation. 
The following is an example of Interlinear Glossed Text:

\begin{exe}  
\ex\label{gloss_eg} Indonesian \citep[p. 237]{sneddon2012indonesian}
	\gll   Mereka di Jakarta sekarang. (\textit{sentence of interest})\\
     	   they in Jakarta now (\textit{gloss line: word-by-word gloss translation})\\
    \glt   `They are in Jakarta now.' (\textit{English translation})  
\end{exe}

The first line in an Interlinear Glossed Text is the sentence of interest in its written form, the second line is a word by word morpheme by morpheme translation, and the third line is the corresponding English translation. 

The glossing data has very interesting properties. First, it contains linguistics information. The glosses are not raw natural data, but are already processed by linguists based on the linguistic theory they adopt. Second, it is a type of big data, because Interlinear Glossed Texts are so widely used in linguistics.
Both natural language processing and linguistics are studying human languages. Gloss is the right `lingua franca' for the two fields. 

Also thanks to the advent of neural net sequence to sequence machine learning, which is a generic algorithm that can learn almost any sequence to sequence mapping, the opportunity to successfully incorporate the gloss line into machine translation is also better than in the past.  

With high expectations on the gloss line information, I conducted a series of machine translation experiments. The results show that the gloss information is a very effective booster for neural net machine translation systems in all conditions. 

The rest of the dissertation is organized as follows: chapter 2 discusses the nature of gloss lines, and argues that they are proper representations of meanings; chapter 3 provides a general overview of machine learning and machine translation; chapter 4, chapter 5 and chapter 6 are a series of neural net machine translation experiments; chapter 7 outlines potential future researches and concludes the dissertation.  